{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336b9395",
   "metadata": {},
   "source": [
    "# Generic Chains Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcb42ef",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b094e82",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "The most elementary type of chain is known as a basic chain, which represents the simplest form of crafting a chain. <br>In this setup, there is only one Language Model (LLM) responsible for receiving an input prompt and using it for generating text.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "43b5cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please install the package as per your requirement :)\n",
    "#!pip install openai==1.10.0\n",
    "#!pip install langchain==0.1.4\n",
    "#!pip install huggingface-hub==0.20.3\n",
    "#!pip install langchain-openai==0.0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6b36c04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a8d7c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below import has been replaced by the later one\n",
    "#from langchain.llms import OpenAI\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5547ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "436017aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"place\"],\n",
    "    template=\"Best places to visit in {place}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2477a555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'place': 'India', 'text': \"\\n\\n1. The Taj Mahal, Agra\\n2. The Golden Temple, Amritsar\\n3. Jaipur, the Pink City\\n4. Goa's beaches and nightlife\\n5. Kerala's backwaters\\n6. Varanasi, the holy city\\n7. Ranthambore National Park for tiger sightings\\n8. Ladakh for its stunning landscapes\\n9. Hampi's ancient ruins\\n10. Jaisalmer's desert and forts\\n11. Darjeeling for tea plantations and trekking\\n12. Mumbai for its bustling city life and Bollywood culture\\n13. Udaipur's romantic lakes and palaces\\n14. Andaman and Nicobar Islands for its beautiful beaches and marine life\\n15. Mysore for its royal heritage and temples.\"}\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run the chain only specifying the input variable.\n",
    "# Recently langchain has replaced 'run' function with 'invoke'\n",
    "print(chain.invoke(\"India\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "58148606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'place': 'India',\n",
       " 'text': '\\n\\n1. The Taj Mahal, Agra\\n2. Varanasi, Uttar Pradesh\\n3. Jaipur, Rajasthan\\n4. Goa\\n5. Kerala backwaters\\n6. Ladakh\\n7. Hampi, Karnataka\\n8. Jaisalmer, Rajasthan\\n9. Darjeeling, West Bengal\\n10. Rishikesh, Uttarakhand\\n11. Mumbai, Maharashtra\\n12. Delhi\\n13. Udaipur, Rajasthan\\n14. Amritsar, Punjab\\n15. Mysore, Karnataka\\n16. Shimla, Himachal Pradesh\\n17. Khajuraho, Madhya Pradesh\\n18. Pushkar, Rajasthan\\n19. Alleppey, Kerala\\n20. Jodhpur, Rajasthan'}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88205e2",
   "metadata": {},
   "source": [
    "## Simple Sequential Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb1850c",
   "metadata": {},
   "source": [
    "<font color='green'>\n",
    "Sequential Chains involves making a series of consecutive calls to the language model.<br> This approach proves especially valuable when there is a need to utilize the output generated from one call as the input for another call.\n",
    "<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "76654563",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain import HuggingFaceHub\n",
    "from langchain_community.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "92f94dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You have to suggest 5 best places names with out details to visit in {place}? \n",
    "\n",
    "YOUR RESPONSE: \n",
    "\"\"\"\n",
    "# PromptTemplate(\n",
    "#     input_variables=[\"place\"],\n",
    "#     template=\"Best places to visit in {place}?\",\n",
    "# )\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"place\"], \n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "77104326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\jdamodhar\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# HF_llm= HuggingFaceHub(repo_id = \"google/flan-t5-large\")\n",
    "HF_llm= HuggingFaceEndpoint(repo_id = \"google/flan-t5-xxl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2578b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "aa350baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "place_chain = LLMChain(llm=HF_llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "d4ea5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Given a list a places, please estimate the expenses to visit all of them in local currency and also the days needed\n",
    "{expenses}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"expenses\"],\n",
    "    template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ef315099",
   "metadata": {},
   "outputs": [],
   "source": [
    "expenses_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "16e97f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = SimpleSequentialChain(chains=[place_chain, expenses_chain], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "98487cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mshimla, shimla, india, dharamshala\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "Based on research and average prices, the estimated expenses for visiting all of the places would be around 25,000 Indian Rupees (INR). This includes accommodation, transportation, food, and entrance fees. The estimated number of days needed to visit all the places would be 6-7 days. This would allow for enough time to explore each place and also account for travel time between the locations. Please note that these estimates may vary depending on personal preferences and travel styles.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = final_chain.invoke(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "a2c09bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m-Mumbai -Agra -Madhya Pradesh -Kerala\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\n",
      "Mumbai:\n",
      "- Transportation (round trip flight from major international airport): INR 20,000\n",
      "- Accommodation (3 nights in a mid-range hotel): INR 10,000\n",
      "- Food and drinks: INR 5,000\n",
      "- Sightseeing and activities: INR 5,000\n",
      "Total estimated expenses for Mumbai: INR 40,000\n",
      "Estimated days needed for Mumbai: 3 days\n",
      "\n",
      "Agra:\n",
      "- Transportation (train or bus from Mumbai): INR 2,000\n",
      "- Accommodation (1 night in a mid-range hotel): INR 3,000\n",
      "- Food and drinks: INR 1,500\n",
      "- Sightseeing and activities: INR 2,500\n",
      "Total estimated expenses for Agra: INR 9,000\n",
      "Estimated days needed for Agra: 1 day\n",
      "\n",
      "Madhya Pradesh:\n",
      "- Transportation (train or bus from Agra): INR 5,000\n",
      "- Accommodation (3 nights in a mid-range hotel): INR 9,000\n",
      "- Food and drinks: INR 4,500\n",
      "- Sightseeing and activities: INR 5,000\n",
      "Total estimated expenses for Madhya Pradesh: INR 23,500\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "HF_llm= HuggingFaceHub(repo_id = \"google/flan-t5-xxl\")\n",
    "# HF_llm= HuggingFaceEndpoint(repo_id = \"google/flan-t5-large\")\n",
    "#llm = OpenAI()\n",
    "template = \"\"\"You have to suggest 5 best places names to visit in {place}? \n",
    "\n",
    "YOUR RESPONSE: \n",
    "\"\"\"\n",
    "# PromptTemplate(\n",
    "#     input_variables=[\"place\"],\n",
    "#     template=\"Best places to visit in {place}?\",\n",
    "# )\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"place\"], \n",
    "    template=template)\n",
    "place_chain = LLMChain(llm=HF_llm, prompt=prompt_template)\n",
    "template = \"\"\"Given a list a places, please estimate the expenses to visit all of them in local currency and also the days needed\n",
    "{expenses}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"expenses\"],\n",
    "    template=template)\n",
    "llm = OpenAI()\n",
    "expenses_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "final_chain = SimpleSequentialChain(chains=[place_chain, expenses_chain], verbose=True)\n",
    "review = final_chain.invoke(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4200a542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m1. Goa\n",
      "2. Jaipur\n",
      "3. Manali\n",
      "4. Agra\n",
      "5. Udaipur\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m1. Goa\n",
      "Expenses: Approximately 20,000 INR for 3-4 days\n",
      "Days Needed: 3-4 days\n",
      "\n",
      "2. Jaipur\n",
      "Expenses: Approximately 15,000 INR for 2-3 days\n",
      "Days Needed: 2-3 days\n",
      "\n",
      "3. Manali\n",
      "Expenses: Approximately 25,000 INR for 4-5 days\n",
      "Days Needed: 4-5 days\n",
      "\n",
      "4. Agra\n",
      "Expenses: Approximately 10,000 INR for 1-2 days\n",
      "Days Needed: 1-2 days\n",
      "\n",
      "5. Udaipur\n",
      "Expenses: Approximately 15,000 INR for 2-3 days\n",
      "Days Needed: 2-3 days\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "HF_llm= HuggingFaceHub(repo_id = \"google/flan-t5-xxl\")\n",
    "# HF_llm= HuggingFaceEndpoint(repo_id = \"google/flan-t5-large\")\n",
    "#llm = OpenAI()\n",
    "template = \"\"\"You have to suggest 5 best places names with out details to visit in {place}? \n",
    "\n",
    "YOUR RESPONSE: \n",
    "\"\"\"\n",
    "# PromptTemplate(\n",
    "#     input_variables=[\"place\"],\n",
    "#     template=\"Best places to visit in {place}?\",\n",
    "# )\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"place\"], \n",
    "    template=template)\n",
    "place_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "template = \"\"\"Given a list a places, please estimate the expenses to visit all of them in local currency and also the days needed\n",
    "{expenses}\n",
    "\n",
    "YOUR RESPONSE:\n",
    "\"\"\"\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"expenses\"],\n",
    "    template=template)\n",
    "llm = OpenAI()\n",
    "expenses_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "final_chain = SimpleSequentialChain(chains=[place_chain, expenses_chain], verbose=True)\n",
    "review = final_chain.invoke(\"India\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817c07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
